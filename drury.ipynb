{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Peter Drury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c6204c5710>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [4.6608, 3.2175, 2.1361, 1.4276, 0.9470, 0.6351, 0.4247, 0.3126, 0.2569, 0.2301,  0.1986]\n",
    "val_loss = [6.6592, 6.5789, 6.8161, 7.1546, 7.4446, 7.7575, 8.0703, 8.3040, 8.4363, 8.6253, 8.6467]\n",
    "\n",
    "plt.plot(val_loss, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2875048f2f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 1000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # use GPU if available - for faster training!\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data, Drury dataset\n",
    "with open('data/drury.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenize the text - convert each character to a unique integer ID - here we are using character-level tokenization\n",
    "There are several methods for tokenization:\n",
    "- character-level tokenization\n",
    "- word-level tokenization\n",
    "- sub-word level tokenization\n",
    " You can also use a pre-trained tokenizer such as [SentencePiece](https://github.com/google/sentencepiece), [TikToken](https://github.com/openai/tiktoken) etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text - convert each character to a unique integer ID - here we are using character-level tokenization\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and test sets\n",
    "We are splitting the data into training and test sets. The training set will be used to train the model and the test set will be used to evaluate the model. We will use 90% of the data for training and 10% for testing.\n",
    "\n",
    "The reason for splitting the dataset is because we do not want a perfect memorization of the dataset. We want the model to generalize well to unseen data. If we do not split the dataset, the model will memorize the training data and will not perform well on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 47, 66,  ..., 55, 49, 66])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # 90/10 train/test split\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211535 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6537, val loss 4.6295\n",
      "step 100: train loss 2.6894, val loss 2.7454\n",
      "step 200: train loss 2.4951, val loss 2.5642\n",
      "step 300: train loss 2.3921, val loss 2.4613\n",
      "step 400: train loss 2.2913, val loss 2.3806\n",
      "step 500: train loss 2.1616, val loss 2.3114\n",
      "step 600: train loss 2.0332, val loss 2.2069\n",
      "step 700: train loss 1.9737, val loss 2.1625\n",
      "step 800: train loss 1.8819, val loss 2.1184\n",
      "step 900: train loss 1.7863, val loss 2.1192\n",
      "step 999: train loss 1.7170, val loss 2.1157\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Drury-like commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Event: Mater Ciapiary8\n",
      "Commentary:\n",
      "Compiontary8\n",
      "Ti\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((2, 2), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=50)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
